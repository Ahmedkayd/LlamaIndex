#  LlamaIndex ChatBot Using ChromaDB & Streamlit (Dockerized)

## Requirements
This project sets up a complete document ingestion and retrieval pipeline using:

- [LlamaIndex](https://github.com/jerryjliu/llama_index)
- [ChromaDB](https://www.trychroma.com/)
- [Streamlit](https://streamlit.io/)
- [Docker](https://docs.docker.com/engine/install/ubuntu/)
- [Docker-compose](https://docs.docker.com/compose/install/linux/)
- [openAI API-Key](https://platform.openai.com)

## ðŸ“‚ Project Structure
```text
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py                # Streamlit frontend
â”‚   â”œâ”€â”€ ingestion.py          # Ingests documents into ChromaDB
â”‚   â”œâ”€â”€ node_postprocessors/  # node postprocessor to optimize node processing
â”‚   â””â”€â”€ llamaindex-docs/      # Folder containing input .html document files
â”œâ”€â”€ chroma_data/              # Persistent ChromaDB storage
â”œâ”€â”€ requirements/             # pip packages to be installed
```
## To run this code locally, youâ€™ll need to:
While this code is configured to use OpenAI, you can use any LLM. If you choose to use a different LLM, be sure to update the code as needed and configure it to connect to your chosen model.
This project is containerized and you can simply run the below commands to test it locally on your machine.

- Install `docker and docker-compose` on your machine.
- Obtain an OpenAI API key.
- clone this repo `git clone git@bitbucket.org:saccounty/dha-dau-miscellaneous-ahmed.git`
- Go to llamaindex directory in the terminal.
- Add your openAI api-key in .env file as `OPENAI_API_KEY=xyz`
- Run `docker-compose up`
- Go to [http://localhost:8504](http://localhost:8504) 

![](src/llamaindex.png)
